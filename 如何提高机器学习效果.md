# 如何提高机器学习效果

在一个问题上有一两个表现不错的算法是一个好的开始，但有时当你花你可以利用的时间和资源得到更好的结果时，那将使你受到更大的激励。

在这篇文章中，你将回顾一些可以使用的方法来进一步的提高性能。

本文来自于[如何提高机器学习效果](https://machinelearningmastery.com/how-to-improve-machine-learning-results/)

当调优算法时，您必须对测试工具给出的结果有很高的信心。这意味着当算法运行时，您必须使用可以减少性能差异的技术。我推荐使用具有较多fold的交叉验证(具体还需依赖于你的数据集。)

![音叉](/photo/tuning-fork.jpg)

- 在这篇文章中你将会学到三种策略：
  - 算法调优
  - 集成
  - 极度的特征工程

# 算法调优

首先从你已经知道的对于你的问题执行较好的算法开始去得到更好的性能。你可以通过研究和调整这些算法的配置来实现这一点。

机器学习算法是参数化的，修改这些参数会影响机器学习的性能。将每个算法参数看作是图上的一个维度，给定参数的值是轴上的一个点。对算法可能的参数来说，三个参数将会构成一个立方，n个参数将会构成一个n维超立方。

算法调优的目标是在超立方体中为你的问题找到一个或多个最佳点。您将依赖您的测试工具进行优化，因此您决不能低估花时间构建受信任的测试工具的重要信。

您可以通过使用自动化方法来解决这个搜索问题，这些方法在可能存在的空间和示例中添加一个网格，在这些空间和网格中可能有较好的算法配置。然后，您可以在优化算法中使用这些点来放大最佳性能。

您可以对许多性能良好的方法重复这个过程，并探索使用每种方法所能达到的最佳效果。我强烈建议该过程是自动化的，并且合理地粗粒度化，因为您可以迅速达到收益递减的点(性能提高的百分比百分比)，而这可能不会转化为生产系统。

算法的参数调整得越好，算法对训练数据和测试工具的偏差就越大。此策略可能是有效的，但它也可能导致更脆弱的模型，这些模型与您的测试工具过于匹配，在实践中表现不佳。

# 集成

集成方法是将多种方法的结果进行组合，以得到改进的结果。当你有多个“足够好”的模型专门针对问题的不同部分时，集成方法会工作得很好。

- 这可以通过许多方式来实现。你可以探索三种集成策略:
  - **Bagging**: 更正式的说法是*Bootstrapped Aggregation*，指的是同一个算法在训练数据的不同子集上进行训练，从而对问题有不同的看法。
  - **Boosting**：在相同的训练数据上训练不同的算法。
  - **Blending**: 更正式的说法是*Stacked Generalization or Stacking*，是指将各种模型的预测作为一个新模型的输入，这个新模型学习如何将这些预测组合成一个整体的预测。

在你尝试过更传统的方法之后，进入集成方法是一个好主意。这样做有两个很好的理由，它们通常比传统方法更复杂，并且传统方法为您提供了一个良好的基础级别，您可以从中改进和借鉴来创建您的集成。

![集成学习](/photo/ensemble.jpg)

# 极度特征工程

前两种策略着眼于从机器学习算法中获取更多信息。这个策略是为了展现出问题的更多结构，以便算法学习。在数据准备中学习了特征分解和聚集，以便更好地将数据归一化用于机器学习算法。在这个策略中，我们把这个想法推向了极限。我称这种策略为极端特征工程，其实术语“特征工程”就足够了。

把你的数据想象成嵌入在其中的复杂的多维结构，机器学习算法知道如何发现和利用这些结构来做决定。您希望将这些结构最大程度上地暴露给算法，以便算法能够最好地工作。困难在于，有些结构可能过于密集或过于复杂，算法在没有帮助的情况下无法找到。您也可以从您的领域专家那里了解到一些此类结构的知识。

将属性广泛的分解为多个特征。从技术上讲，使用这种策略所做的是将依赖关系和非线性关系减少为更简单的独立线性关系。

- 这可能是个陌生的想法，所以这里有三个例子:
  - **Categorical**：你有一个具有值[红，绿，蓝]的分类属性，你可以把它分成3个红色，绿色和蓝色的二进制属性，并给每个实例一个1或0的值。
  ![分类特征分解](/photo/分类特征分解.png)
  - **Real**: 你有一个实值量它的值从0到1000。您可以创建10个二进制属性，每个属性表示一组值(0-99表示bin 1, 100-199表示bin 2，等等)，并为每个实例分配一个二进制值(1/0)。

我建议一次执行一个步骤，为每次修改创建一个新的测试/训练数据集，然后测试数据集上的算法。这将让您直观地了解数据中的属性和特性，这些属性和特性或多或少地向算法提供信息，以及它们对性能度量的影响。您可以使用这些结果来指导进一步的极端分解或聚合。

# 总结

- 在这篇文章中，你学习了三种从机器学习算法中获得改进结果的策略:
  - 发现最佳模型的算法调整被视为模型参数空间的搜索问题。
  - 集成是指将多个模型的预测进行组合。
  - 极端特征工程，将数据准备中所看到的属性分解和聚集推到极限。

# 资源

- 如果您想更深入地研究这个主题，请参阅下面的参考资料。
  - [Machine Learning for Hackers](https://amzn.to/3kNsV92), Chapter 12: Model Comparison
  - [Data Mining: Practical Machine Learning Tools and Techniques](https://amzn.to/340LRLA), Chapter 7: Transformations: Engineering the input and output
  - [The Elements of Statistical Learning: Data Mining, Inference, and Prediction](https://amzn.to/31SA3bt), Chapter 16: Ensemble Learning

  您还有任何关于这篇指南的问题吗，欢迎您通过我的邮箱联系我：A2711985388@163.com

  本文翻译自[Jason Brownlee PhD](https://machinelearningmastery.com/how-to-improve-machine-learning-results/)
